{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Robot Framework Expert Fine-Tune (Unsloth)\n",
        "\n",
        "This notebook fine-tunes a small instruct model using QLoRA and pushes the adapter to Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip -q install -r requirements-train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, subprocess, json\n",
        "repo_url = \"{{REPO_URL}}\"\n",
        "if not repo_url:\n",
        "    raise SystemExit('REPO_URL is missing')\n",
        "!git clone {repo_url} repo\n",
        "%cd repo\n",
        "print('Repo cloned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN','')\n",
        "if not os.environ['HF_TOKEN']:\n",
        "    raise SystemExit('HF_TOKEN is required')\n",
        "print('HF_TOKEN set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "dataset_repo = \"{{DATASET_REPO}}\"\n",
        "train_path = Path('dataset/train.jsonl')\n",
        "eval_path = Path('dataset/eval.jsonl')\n",
        "if train_path.exists() and eval_path.exists():\n",
        "    print('Using local dataset')\n",
        "elif dataset_repo:\n",
        "    print(f'Downloading dataset {dataset_repo}')\n",
        "    ds = load_dataset(dataset_repo)\n",
        "    Path('dataset').mkdir(exist_ok=True)\n",
        "    ds['train'].to_json(train_path, orient='records', lines=True)\n",
        "    ds['test' if 'test' in ds else 'validation' if 'validation' in ds else 'train'].to_json(eval_path, orient='records', lines=True)\n",
        "else:\n",
        "    print('Building dataset locally (skip validation)')\n",
        "    !python tools/build_dataset.py --skip-validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "base_model = \"{{BASE_MODEL}}\"\n",
        "fallback_model = \"{{FALLBACK_MODEL}}\"\n",
        "hf_repo = \"{{HF_REPO}}\"\n",
        "seed = {{SEED}}\n",
        "!python train/train_unsloth.py --base-model {base_model} --fallback-model {fallback_model} --hf-repo {hf_repo} --seed {seed}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "finetune_unsloth.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}